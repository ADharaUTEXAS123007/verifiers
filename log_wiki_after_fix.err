
Lmod is automatically replacing "nvidia/24.7" with "gcc/13.2.0".


Due to MODULEPATH changes, the following have been reloaded:
  1) openmpi/5.0.5

The following have been reloaded with a version change:
  1) nvpl/24.7 => nvpl/25.9


Due to MODULEPATH changes, the following have been reloaded:
  1) openmpi/5.0.5

DeprecationWarning: 'source deactivate' is deprecated. Use 'conda deactivate'.
/scratch/09143/arnabd/newproj/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/scratch/09143/arnabd/newproj/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
2026-01-24 08:43:57 - verifiers.utils.install_utils - INFO - Installing wiki-search from environments/wiki_search...
2026-01-24 08:44:02 - verifiers.utils.install_utils - INFO - Successfully installed wiki-search
[W124 08:44:03.270810298 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
[0;36m(EngineCore_DP0 pid=1343968)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]
2026-01-24 08:44:10 - verifiers.utils.env_utils - INFO - Loading environment: wiki-search
2026-01-24 08:44:11 - verifiers.utils.env_utils - INFO - Using provided args: judge_model=dummy, judge_timeout=300.0, max_turns=10
2026-01-24 08:44:11 - verifiers.utils.env_utils - INFO - Using default args: judge_base_url='https://api.openai.com/v1', chroma_db_dir='.chroma_db', judge_api_key_var='OPENAI_API_KEY', corpus_dataset='willcb/rare-wiki-pages', embed_api_key_var='OPENAI_API_KEY', embed_model='text-embedding-3-small', corpus_split='train', embed_base_url='https://api.openai.com/v1'
[0;36m(EngineCore_DP0 pid=1343968)[0;0m Loading safetensors checkpoint shards:  33% Completed | 1/3 [00:06<00:13,  6.68s/it]
2026-01-24 08:44:17 - verifiers.rubrics.rubric.RubricGroup - WARNING - Adding reward function to the first rubric in the group.
2026-01-24 08:44:17 - verifiers.utils.env_utils - INFO - Successfully loaded environment 'wiki-search'
/scratch/09143/arnabd/newproj/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[0;36m(EngineCore_DP0 pid=1343968)[0;0m Loading safetensors checkpoint shards:  67% Completed | 2/3 [00:16<00:08,  8.69s/it]
[0;36m(EngineCore_DP0 pid=1343968)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [00:16<00:00,  4.80s/it]
[0;36m(EngineCore_DP0 pid=1343968)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [00:16<00:00,  5.65s/it]
[0;36m(EngineCore_DP0 pid=1343968)[0;0m 
INFO:     Started server process [1343891]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:00<00:00,  3.42it/s]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:00<00:00,  3.14it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.70it/s]
2026-01-24 08:45:09 - verifiers.rl.inference.client - INFO - Server is up!
2026-01-24 08:45:09 - verifiers.rl.inference.client - INFO - vLLM world size: 1
2026-01-24 08:45:09 - verifiers.rl.inference.client - INFO - Client rank: 1, total world size: 2
2026-01-24 08:45:09 - verifiers.rl.inference.client - INFO - Initializing PyNcclCommunicator on device 0, rank 1, world_size 2
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.
Processing 32 groups (512 total rollouts):   0%|          | 0/32 [00:00<?, ?it/s, reward=?]wandb: Currently logged in as: adhara (sparkcognition-services) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run bxlui5vt
wandb: Tracking run with wandb version 0.23.1
wandb: Run data is saved locally in /scratch/09143/arnabd/newproj/wandb/wandb/run-20260124_084511-bxlui5vt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wiki-search
wandb: â­ï¸ View project at https://wandb.ai/sparkcognition-services/wiki-search
wandb: ðŸš€ View run at https://wandb.ai/sparkcognition-services/wiki-search/runs/bxlui5vt
wandb: Detected [mcp, openai, agents, verifiers] in use.
wandb: Use W&B Weave for improved LLM call tracing. Weave is installed but not imported. Add `import weave` to the top of your script.
wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/

  0%|          | 0/500 [00:00<?, ?it/s][A2026-01-24 08:45:22 - verifiers.rl.trainer.trainer - INFO - Waiting for generation to finish before syncing.
2026-01-24 08:45:27 - verifiers.rl.trainer.trainer - INFO - Waiting for generation to finish before syncing.
2026-01-24 08:45:32 - verifiers.rl.trainer.trainer - INFO - Waiting for generation to finish before syncing.
2026-01-24 08:45:37 - verifiers.rl.trainer.trainer - INFO - Waiting for generation to finish before syncing.
2026-01-24 08:45:42 - verifiers.rl.trainer.trainer - INFO - Waiting for generation to finish before syncing.
2026-01-24 08:45:47 - verifiers.rl.trainer.trainer - INFO - Waiting for generation to finish before syncing.
2026-01-24 08:45:52 - verifiers.rl.trainer.trainer - INFO - Waiting for generation to finish before syncing.
2026-01-24 08:45:57 - verifiers.rl.trainer.trainer - INFO - Waiting for generation to finish before syncing.
2026-01-24 08:46:02 - verifiers.rl.trainer.trainer - INFO - Waiting for generation to finish before syncing.
2026-01-24 08:46:07 - verifiers.rl.trainer.trainer - INFO - Waiting for generation to finish before syncing.
2026-01-24 08:46:12 - verifiers.rl.trainer.trainer - INFO - Waiting for generation to finish before syncing.
Processing 32 groups (512 total rollouts):   3%|â–Ž         | 1/32 [01:06<34:09, 66.11s/it, reward=?]Processing 32 groups (512 total rollouts):   3%|â–Ž         | 1/32 [01:06<34:09, 66.11s/it, reward=1.000]2026-01-24 08:46:18 - verifiers.rl.trainer.trainer - INFO - Waiting for generation to finish before syncing.
Processing 32 groups (512 total rollouts):   6%|â–‹         | 2/32 [01:08<14:26, 28.87s/it, reward=1.000]Processing 32 groups (512 total rollouts):   6%|â–‹         | 2/32 [01:08<14:26, 28.87s/it, reward=1.000]2026-01-24 08:46:23 - verifiers.rl.trainer.trainer - INFO - Waiting for generation to finish before syncing.
Processing 32 groups (512 total rollouts):   9%|â–‰         | 3/32 [01:13<08:40, 17.95s/it, reward=1.000]Processing 32 groups (512 total rollouts):   9%|â–‰         | 3/32 [01:13<08:40, 17.95s/it, reward=1.000]Processing 32 groups (512 total rollouts):  12%|â–ˆâ–Ž        | 4/32 [01:14<05:08, 11.03s/it, reward=1.000]Processing 32 groups (512 total rollouts):  12%|â–ˆâ–Ž        | 4/32 [01:14<05:08, 11.03s/it, reward=1.000]2026-01-24 08:46:28 - verifiers.rl.trainer.trainer - INFO - Waiting for generation to finish before syncing.
2026-01-24 08:46:33 - verifiers.rl.trainer.trainer - INFO - Waiting for generation to finish before syncing.
Processing 32 groups (512 total rollouts):  16%|â–ˆâ–Œ        | 5/32 [01:24<04:47, 10.66s/it, reward=1.000]Processing 32 groups (512 total rollouts):  16%|â–ˆâ–Œ        | 5/32 [01:24<04:47, 10.66s/it, reward=1.000]Processing 32 groups (512 total rollouts):  19%|â–ˆâ–‰        | 6/32 [01:24<03:05,  7.13s/it, reward=1.000]Processing 32 groups (512 total rollouts):  19%|â–ˆâ–‰        | 6/32 [01:24<03:05,  7.13s/it, reward=1.000]Processing 32 groups (512 total rollouts):  22%|â–ˆâ–ˆâ–       | 7/32 [01:24<02:58,  7.13s/it, reward=1.000]Processing 32 groups (512 total rollouts):  25%|â–ˆâ–ˆâ–Œ       | 8/32 [01:26<01:40,  4.17s/it, reward=1.000]Processing 32 groups (512 total rollouts):  25%|â–ˆâ–ˆâ–Œ       | 8/32 [01:26<01:40,  4.17s/it, reward=1.000]Processing 32 groups (512 total rollouts):  28%|â–ˆâ–ˆâ–Š       | 9/32 [01:27<01:12,  3.16s/it, reward=1.000]Processing 32 groups (512 total rollouts):  28%|â–ˆâ–ˆâ–Š       | 9/32 [01:27<01:12,  3.16s/it, reward=1.000]Processing 32 groups (512 total rollouts):  31%|â–ˆâ–ˆâ–ˆâ–      | 10/32 [01:27<00:53,  2.45s/it, reward=1.000]Processing 32 groups (512 total rollouts):  31%|â–ˆâ–ˆâ–ˆâ–      | 10/32 [01:27<00:53,  2.45s/it, reward=1.000]2026-01-24 08:46:38 - verifiers.rl.trainer.trainer - INFO - Waiting for generation to finish before syncing.
Processing 32 groups (512 total rollouts):  34%|â–ˆâ–ˆâ–ˆâ–      | 11/32 [01:27<00:51,  2.45s/it, reward=1.000]Processing 32 groups (512 total rollouts):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 12/32 [01:27<00:28,  1.44s/it, reward=1.000]Processing 32 groups (512 total rollouts):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 12/32 [01:27<00:28,  1.44s/it, reward=1.000]Processing 32 groups (512 total rollouts):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 13/32 [01:28<00:21,  1.14s/it, reward=1.000]Processing 32 groups (512 total rollouts):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 13/32 [01:28<00:21,  1.14s/it, reward=1.000]Processing 32 groups (512 total rollouts):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/32 [01:28<00:16,  1.09it/s, reward=1.000]Processing 32 groups (512 total rollouts):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/32 [01:28<00:16,  1.09it/s, reward=1.000]Processing 32 groups (512 total rollouts):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 15/32 [01:28<00:15,  1.09it/s, reward=1.000]Processing 32 groups (512 total rollouts):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 16/32 [01:28<00:14,  1.09it/s, reward=1.000]Processing 32 groups (512 total rollouts):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 17/32 [01:28<00:07,  2.13it/s, reward=1.000]Processing 32 groups (512 total rollouts):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 17/32 [01:28<00:07,  2.13it/s, reward=1.000]Processing 32 groups (512 total rollouts):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 18/32 [01:28<00:05,  2.47it/s, reward=1.000]Processing 32 groups (512 total rollouts):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 18/32 [01:28<00:05,  2.47it/s, reward=1.000]Processing 32 groups (512 total rollouts):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 19/32 [01:28<00:04,  2.62it/s, reward=1.000]Processing 32 groups (512 total rollouts):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 19/32 [01:28<00:04,  2.62it/s, reward=1.000]Processing 32 groups (512 total rollouts):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 20/32 [01:29<00:03,  3.08it/s, reward=1.000]Processing 32 groups (512 total rollouts):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 20/32 [01:29<00:03,  3.08it/s, reward=1.000]Processing 32 groups (512 total rollouts):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 21/32 [01:29<00:03,  3.02it/s, reward=1.000]Processing 32 groups (512 total rollouts):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 21/32 [01:29<00:03,  3.02it/s, reward=1.000]Processing 32 groups (512 total rollouts):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 22/32 [01:30<00:04,  2.25it/s, reward=1.000]Processing 32 groups (512 total rollouts):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 22/32 [01:30<00:04,  2.25it/s, reward=1.000]Processing 32 groups (512 total rollouts):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 23/32 [01:30<00:03,  2.71it/s, reward=1.000]Processing 32 groups (512 total rollouts):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 23/32 [01:30<00:03,  2.71it/s, reward=1.000]Processing 32 groups (512 total rollouts):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 24/32 [01:30<00:03,  2.35it/s, reward=1.000]Processing 32 groups (512 total rollouts):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 24/32 [01:30<00:03,  2.35it/s, reward=1.000]Processing 32 groups (512 total rollouts):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 25/32 [01:31<00:02,  2.35it/s, reward=1.000]Processing 32 groups (512 total rollouts):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 26/32 [01:31<00:01,  3.26it/s, reward=1.000]Processing 32 groups (512 total rollouts):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 26/32 [01:31<00:01,  3.26it/s, reward=1.000]Processing 32 groups (512 total rollouts):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/32 [01:31<00:01,  3.24it/s, reward=1.000]Processing 32 groups (512 total rollouts):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/32 [01:31<00:01,  3.24it/s, reward=1.000]Processing 32 groups (512 total rollouts):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 28/32 [01:32<00:01,  2.43it/s, reward=1.000]Processing 32 groups (512 total rollouts):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 28/32 [01:32<00:01,  2.43it/s, reward=1.000]2026-01-24 08:46:43 - verifiers.rl.trainer.trainer - INFO - Waiting for generation to finish before syncing.
Processing 32 groups (512 total rollouts):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 29/32 [01:33<00:01,  1.77it/s, reward=1.000]Processing 32 groups (512 total rollouts):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 29/32 [01:33<00:01,  1.77it/s, reward=1.000]Processing 32 groups (512 total rollouts):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 30/32 [01:33<00:01,  1.77it/s, reward=1.000]Processing 32 groups (512 total rollouts):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 30/32 [01:33<00:01,  1.77it/s, reward=1.000]Processing 32 groups (512 total rollouts):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 31/32 [01:35<00:00,  1.23it/s, reward=1.000]Processing 32 groups (512 total rollouts):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 31/32 [01:35<00:00,  1.23it/s, reward=1.000]2026-01-24 08:46:48 - verifiers.rl.trainer.trainer - INFO - Waiting for generation to finish before syncing.
Processing 32 groups (512 total rollouts): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [01:39<00:00,  1.82s/it, reward=1.000]Processing 32 groups (512 total rollouts): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [01:39<00:00,  1.82s/it, reward=1.000]Processing 32 groups (512 total rollouts): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [01:39<00:00,  3.11s/it, reward=1.000]
Processing 32 groups (512 total rollouts):   0%|          | 0/32 [00:00<?, ?it/s, reward=?]Processing 32 groups (512 total rollouts):   3%|â–Ž         | 1/32 [00:07<03:55,  7.61s/it, reward=?]Processing 32 groups (512 total rollouts):   3%|â–Ž         | 1/32 [00:07<03:55,  7.61s/it, reward=1.000]Processing 32 groups (512 total rollouts):   6%|â–‹         | 2/32 [00:15<03:53,  7.79s/it, reward=1.000]Processing 32 groups (512 total rollouts):   6%|â–‹         | 2/32 [00:15<03:53,  7.79s/it, reward=1.000]Processing 32 groups (512 total rollouts):   9%|â–‰         | 3/32 [00:16<02:16,  4.71s/it, reward=1.000]Processing 32 groups (512 total rollouts):   9%|â–‰         | 3/32 [00:16<02:16,  4.71s/it, reward=1.000]Processing 32 groups (512 total rollouts):  12%|â–ˆâ–Ž        | 4/32 [00:16<02:11,  4.71s/it, reward=1.000]Processing 32 groups (512 total rollouts):  16%|â–ˆâ–Œ        | 5/32 [00:18<01:10,  2.63s/it, reward=1.000]Processing 32 groups (512 total rollouts):  16%|â–ˆâ–Œ        | 5/32 [00:18<01:10,  2.63s/it, reward=1.000]Processing 32 groups (512 total rollouts):  19%|â–ˆâ–‰        | 6/32 [00:18<00:50,  1.93s/it, reward=1.000]Processing 32 groups (512 total rollouts):  19%|â–ˆâ–‰        | 6/32 [00:18<00:50,  1.93s/it, reward=1.000]Processing 32 groups (512 total rollouts):  22%|â–ˆâ–ˆâ–       | 7/32 [00:21<00:51,  2.05s/it, reward=1.000]Processing 32 groups (512 total rollouts):  22%|â–ˆâ–ˆâ–       | 7/32 [00:21<00:51,  2.05s/it, reward=1.000]Processing 32 groups (512 total rollouts):  25%|â–ˆâ–ˆâ–Œ       | 8/32 [00:22<00:40,  1.69s/it, reward=1.000]Processing 32 groups (512 total rollouts):  25%|â–ˆâ–ˆâ–Œ       | 8/32 [00:22<00:40,  1.69s/it, reward=1.000]Processing 32 groups (512 total rollouts):  28%|â–ˆâ–ˆâ–Š       | 9/32 [00:27<01:04,  2.81s/it, reward=1.000]Processing 32 groups (512 total rollouts):  28%|â–ˆâ–ˆâ–Š       | 9/32 [00:27<01:04,  2.81s/it, reward=1.000]Processing 32 groups (512 total rollouts):  31%|â–ˆâ–ˆâ–ˆâ–      | 10/32 [00:28<00:50,  2.30s/it, reward=1.000]Processing 32 groups (512 total rollouts):  31%|â–ˆâ–ˆâ–ˆâ–      | 10/32 [00:28<00:50,  2.30s/it, reward=1.000]Processing 32 groups (512 total rollouts):  34%|â–ˆâ–ˆâ–ˆâ–      | 11/32 [00:32<00:58,  2.78s/it, reward=1.000]Processing 32 groups (512 total rollouts):  34%|â–ˆâ–ˆâ–ˆâ–      | 11/32 [00:32<00:58,  2.78s/it, reward=1.000]Processing 32 groups (512 total rollouts):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 12/32 [00:32<00:40,  2.02s/it, reward=1.000]Processing 32 groups (512 total rollouts):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 12/32 [00:32<00:40,  2.02s/it, reward=1.000]Processing 32 groups (512 total rollouts):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 13/32 [00:32<00:27,  1.45s/it, reward=1.000]Processing 32 groups (512 total rollouts):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 13/32 [00:32<00:27,  1.45s/it, reward=1.000]Processing 32 groups (512 total rollouts):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/32 [00:32<00:19,  1.06s/it, reward=1.000]Processing 32 groups (512 total rollouts):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/32 [00:32<00:19,  1.06s/it, reward=1.000]Processing 32 groups (512 total rollouts):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 15/32 [00:33<00:13,  1.28it/s, reward=1.000]Processing 32 groups (512 total rollouts):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 15/32 [00:33<00:13,  1.28it/s, reward=1.000]Processing 32 groups (512 total rollouts):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 16/32 [00:33<00:09,  1.70it/s, reward=1.000]Processing 32 groups (512 total rollouts):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 16/32 [00:33<00:09,  1.70it/s, reward=1.000]Processing 32 groups (512 total rollouts):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 17/32 [00:33<00:08,  1.70it/s, reward=1.000]Processing 32 groups (512 total rollouts):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 18/32 [00:33<00:08,  1.70it/s, reward=1.000]Processing 32 groups (512 total rollouts):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 19/32 [00:33<00:07,  1.70it/s, reward=1.000]Processing 32 groups (512 total rollouts):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 20/32 [00:33<00:03,  3.39it/s, reward=1.000]Processing 32 groups (512 total rollouts):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 20/32 [00:33<00:03,  3.39it/s, reward=1.000]Processing 32 groups (512 total rollouts):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 21/32 [00:33<00:03,  3.52it/s, reward=1.000]Processing 32 groups (512 total rollouts):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 21/32 [00:33<00:03,  3.52it/s, reward=1.000]Processing 32 groups (512 total rollouts):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 22/32 [00:34<00:02,  3.88it/s, reward=1.000]Processing 32 groups (512 total rollouts):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 22/32 [00:34<00:02,  3.88it/s, reward=1.000]Processing 32 groups (512 total rollouts):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 23/32 [00:34<00:02,  3.88it/s, reward=1.000]Processing 32 groups (512 total rollouts):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 24/32 [00:34<00:02,  3.88it/s, reward=1.000]Processing 32 groups (512 total rollouts):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 25/32 [00:34<00:01,  6.34it/s, reward=1.000]Processing 32 groups (512 total rollouts):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 25/32 [00:34<00:01,  6.34it/s, reward=1.000]Processing 32 groups (512 total rollouts):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 26/32 [00:34<00:00,  6.34it/s, reward=1.000]Processing 32 groups (512 total rollouts):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/32 [00:34<00:00,  6.91it/s, reward=1.000]Processing 32 groups (512 total rollouts):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/32 [00:34<00:00,  6.91it/s, reward=1.000]Processing 32 groups (512 total rollouts):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 28/32 [00:34<00:00,  6.91it/s, reward=1.000]Processing 32 groups (512 total rollouts):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 29/32 [00:35<00:00,  3.16it/s, reward=1.000]Processing 32 groups (512 total rollouts):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 29/32 [00:35<00:00,  3.16it/s, reward=1.000]Processing 32 groups (512 total rollouts):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 30/32 [00:37<00:01,  1.69it/s, reward=1.000]Processing 32 groups (512 total rollouts):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 30/32 [00:37<00:01,  1.69it/s, reward=1.000]Processing 32 groups (512 total rollouts):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 31/32 [00:38<00:00,  1.90it/s, reward=1.000]Processing 32 groups (512 total rollouts):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 31/32 [00:38<00:00,  1.90it/s, reward=1.000]Processing 32 groups (512 total rollouts): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:43<00:00,  1.62s/it, reward=1.000]Processing 32 groups (512 total rollouts): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:43<00:00,  1.62s/it, reward=1.000]Processing 32 groups (512 total rollouts): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:43<00:00,  1.36s/it, reward=1.000]

  0%|          | 1/500 [06:19<52:37:11, 379.62s/it][A
                                                   [A
  0%|          | 1/500 [06:22<52:37:11, 379.62s/it][A2026-01-24 08:51:41 - verifiers.rl.trainer.trainer - INFO - Starting weight sync to vLLM
2026-01-24 08:51:42 - verifiers.rl.trainer.trainer - INFO - Resetting prefix cache.
Processing 32 groups (512 total rollouts):   0%|          | 0/32 [00:00<?, ?it/s, reward=?]Processing 32 groups (512 total rollouts):   3%|â–Ž         | 1/32 [00:07<03:57,  7.67s/it, reward=?]Processing 32 groups (512 total rollouts):   3%|â–Ž         | 1/32 [00:07<03:57,  7.67s/it, reward=1.000]Processing 32 groups (512 total rollouts):   6%|â–‹         | 2/32 [00:26<07:08, 14.28s/it, reward=1.000]Processing 32 groups (512 total rollouts):   6%|â–‹         | 2/32 [00:26<07:08, 14.28s/it, reward=1.000]Processing 32 groups (512 total rollouts):   9%|â–‰         | 3/32 [00:31<04:45,  9.85s/it, reward=1.000]Processing 32 groups (512 total rollouts):   9%|â–‰         | 3/32 [00:31<04:45,  9.85s/it, reward=1.000]Processing 32 groups (512 total rollouts):  12%|â–ˆâ–Ž        | 4/32 [00:31<02:49,  6.06s/it, reward=1.000]Processing 32 groups (512 total rollouts):  12%|â–ˆâ–Ž        | 4/32 [00:31<02:49,  6.06s/it, reward=1.000]Processing 32 groups (512 total rollouts):  16%|â–ˆâ–Œ        | 5/32 [00:31<02:43,  6.06s/it, reward=1.000]Processing 32 groups (512 total rollouts):  19%|â–ˆâ–‰        | 6/32 [00:31<02:37,  6.06s/it, reward=1.000]Processing 32 groups (512 total rollouts):  22%|â–ˆâ–ˆâ–       | 7/32 [00:31<00:57,  2.30s/it, reward=1.000]Processing 32 groups (512 total rollouts):  22%|â–ˆâ–ˆâ–       | 7/32 [00:31<00:57,  2.30s/it, reward=1.000]Processing 32 groups (512 total rollouts):  25%|â–ˆâ–ˆâ–Œ       | 8/32 [00:31<00:55,  2.30s/it, reward=1.000]Processing 32 groups (512 total rollouts):  28%|â–ˆâ–ˆâ–Š       | 9/32 [00:31<00:52,  2.30s/it, reward=1.000]Processing 32 groups (512 total rollouts):  31%|â–ˆâ–ˆâ–ˆâ–      | 10/32 [00:31<00:50,  2.30s/it, reward=1.000]Processing 32 groups (512 total rollouts):  34%|â–ˆâ–ˆâ–ˆâ–      | 11/32 [00:31<00:22,  1.07s/it, reward=1.000]Processing 32 groups (512 total rollouts):  34%|â–ˆâ–ˆâ–ˆâ–      | 11/32 [00:31<00:22,  1.07s/it, reward=1.000]Processing 32 groups (512 total rollouts):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 12/32 [00:33<00:21,  1.07s/it, reward=1.000]Processing 32 groups (512 total rollouts):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 13/32 [00:33<00:19,  1.02s/it, reward=1.000]Processing 32 groups (512 total rollouts):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 13/32 [00:33<00:19,  1.02s/it, reward=1.000]Processing 32 groups (512 total rollouts):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 14/32 [00:33<00:18,  1.02s/it, reward=1.000]Processing 32 groups (512 total rollouts):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 15/32 [00:33<00:12,  1.34it/s, reward=1.000]Processing 32 groups (512 total rollouts):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 15/32 [00:33<00:12,  1.34it/s, reward=1.000]Processing 32 groups (512 total rollouts):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 16/32 [00:33<00:11,  1.34it/s, reward=1.000]Processing 32 groups (512 total rollouts):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 17/32 [00:34<00:08,  1.75it/s, reward=1.000]Processing 32 groups (512 total rollouts):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 17/32 [00:34<00:08,  1.75it/s, reward=1.000]Processing 32 groups (512 total rollouts):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 18/32 [00:34<00:08,  1.70it/s, reward=1.000]Processing 32 groups (512 total rollouts):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 18/32 [00:34<00:08,  1.70it/s, reward=1.000]Processing 32 groups (512 total rollouts):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 19/32 [00:34<00:06,  1.93it/s, reward=1.000]Processing 32 groups (512 total rollouts):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 19/32 [00:34<00:06,  1.93it/s, reward=1.000]Processing 32 groups (512 total rollouts):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 20/32 [00:35<00:06,  1.90it/s, reward=1.000]Processing 32 groups (512 total rollouts):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 20/32 [00:35<00:06,  1.90it/s, reward=1.000]Processing 32 groups (512 total rollouts):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 21/32 [00:35<00:04,  2.35it/s, reward=1.000]Processing 32 groups (512 total rollouts):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 21/32 [00:35<00:04,  2.35it/s, reward=1.000]Processing 32 groups (512 total rollouts):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 22/32 [00:36<00:05,  1.94it/s, reward=1.000]Processing 32 groups (512 total rollouts):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 22/32 [00:36<00:05,  1.94it/s, reward=1.000]Processing 32 groups (512 total rollouts):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 23/32 [00:36<00:03,  2.46it/s, reward=1.000]Processing 32 groups (512 total rollouts):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 23/32 [00:36<00:03,  2.46it/s, reward=1.000]Processing 32 groups (512 total rollouts):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 24/32 [00:36<00:03,  2.46it/s, reward=1.000]Processing 32 groups (512 total rollouts):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 25/32 [00:36<00:02,  2.91it/s, reward=1.000]Processing 32 groups (512 total rollouts):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 25/32 [00:36<00:02,  2.91it/s, reward=1.000]Processing 32 groups (512 total rollouts):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 26/32 [00:37<00:02,  2.91it/s, reward=1.000]Processing 32 groups (512 total rollouts):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/32 [00:37<00:01,  3.69it/s, reward=1.000]Processing 32 groups (512 total rollouts):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 27/32 [00:37<00:01,  3.69it/s, reward=1.000]Processing 32 groups (512 total rollouts):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 28/32 [00:37<00:01,  3.69it/s, reward=1.000]Processing 32 groups (512 total rollouts):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 29/32 [00:38<00:00,  3.20it/s, reward=1.000]Processing 32 groups (512 total rollouts):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 29/32 [00:38<00:00,  3.20it/s, reward=1.000]Processing 32 groups (512 total rollouts):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 30/32 [00:39<00:01,  1.81it/s, reward=1.000]Processing 32 groups (512 total rollouts):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 30/32 [00:39<00:01,  1.81it/s, reward=1.000]Processing 32 groups (512 total rollouts):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 31/32 [00:39<00:00,  1.81it/s, reward=1.000]Processing 32 groups (512 total rollouts): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:41<00:00,  1.52it/s, reward=1.000]Processing 32 groups (512 total rollouts): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:41<00:00,  1.52it/s, reward=1.000]Processing 32 groups (512 total rollouts): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:41<00:00,  1.29s/it, reward=1.000]
Traceback (most recent call last):
  File "/scratch/09143/arnabd/newproj/.venv/bin/vf-train", line 10, in <module>
    sys.exit(main())
             ^^^^^^
  File "/scratch/09143/arnabd/newproj3/verifiers_mybranch/verifiers/verifiers/scripts/train.py", line 36, in main
    trainer.train()
  File "/scratch/09143/arnabd/newproj/.venv/lib/python3.12/site-packages/transformers/trainer.py", line 2325, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/scratch/09143/arnabd/newproj3/verifiers_mybranch/verifiers/verifiers/rl/trainer/trainer.py", line 403, in _inner_training_loop
    return super()._inner_training_loop(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/09143/arnabd/newproj/.venv/lib/python3.12/site-packages/transformers/trainer.py", line 2674, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/09143/arnabd/newproj3/verifiers_mybranch/verifiers/verifiers/rl/trainer/trainer.py", line 198, in training_step
    trainer_logprobs, entropies = self.get_logprobs(model, input_ids, attn_mask, batch_size=chunk_size)
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/09143/arnabd/newproj3/verifiers_mybranch/verifiers/verifiers/rl/trainer/trainer.py", line 300, in get_logprobs
    logits = model(
             ^^^^^^
  File "/scratch/09143/arnabd/newproj/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/09143/arnabd/newproj/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/09143/arnabd/newproj/.venv/lib/python3.12/site-packages/accelerate/utils/operations.py", line 819, in forward
    return model_forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/09143/arnabd/newproj/.venv/lib/python3.12/site-packages/accelerate/utils/operations.py", line 807, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/09143/arnabd/newproj/.venv/lib/python3.12/site-packages/accelerate/utils/operations.py", line 786, in convert_to_fp32
    return recursively_apply(_convert_to_fp32, tensor, test_type=_is_fp16_bf16_tensor)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/09143/arnabd/newproj/.venv/lib/python3.12/site-packages/accelerate/utils/operations.py", line 120, in recursively_apply
    k: recursively_apply(
       ^^^^^^^^^^^^^^^^^^
  File "/scratch/09143/arnabd/newproj/.venv/lib/python3.12/site-packages/accelerate/utils/operations.py", line 127, in recursively_apply
    return func(data, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/09143/arnabd/newproj/.venv/lib/python3.12/site-packages/accelerate/utils/operations.py", line 778, in _convert_to_fp32
    return tensor.float()
           ^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 9.18 GiB. GPU 0 has a total capacity of 95.00 GiB of which 8.35 GiB is free. Including non-PyTorch memory, this process has 86.64 GiB memory in use. Of the allocated memory 81.54 GiB is allocated by PyTorch, and 2.42 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[W124 08:52:38.494307342 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
srun: error: c608-141: task 0: Exited with exit code 1
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
srun: got SIGCONT
slurmstepd: error: *** JOB 550019 ON c608-132 CANCELLED AT 2026-01-24T08:56:47 ***
srun: forcing job termination
slurmstepd: error: *** STEP 550019.0 ON c608-132 CANCELLED AT 2026-01-24T08:56:47 ***
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
[rank0]:[W124 08:56:47.545145978 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[W124 08:56:47.097653909 AllocatorConfig.cpp:28] Warning: PYTORCH_CUDA_ALLOC_CONF is deprecated, use PYTORCH_ALLOC_CONF instead (function operator())
